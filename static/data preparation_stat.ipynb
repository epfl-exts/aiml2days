{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup Google Colab by running this cell only once (ignore this if run locally) {display-mode: \"form\"}\n",
    "import sys \n",
    "if 'google.colab' in sys.modules:\n",
    "    # Clone GitHub repository\n",
    "    !git clone https://github.com/epfl-exts/aml24-master-class.git\n",
    "        \n",
    "    # Copy files required to run the code\n",
    "    !cp -r \"aml24-master-class/text_classification/data\" \"aml24-master-class/text_classification/tools.py\" .\n",
    "    \n",
    "    # Install packages via pip\n",
    "    !pip install -r \"aml24-master-class/colab-requirements.txt\"\n",
    "    \n",
    "    # Restart Runtime\n",
    "    import os\n",
    "    os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "# Data\n",
    "\n",
    "We will use the [SpamAssassin](https://spamassassin.apache.org/) public email corpus. This dataset contains ~6'000 labeled emails. If you want to learn more about this dataset, check [this](https://spamassassin.apache.org/old/publiccorpus/). (*Note: Datasets of text are called corpora and samples are called documents.*) \n",
    "\n",
    "The dataset has been downloaded for you and is available in the *data* folder.\n",
    "\n",
    "The dataset has been labelled, i.e. we are told whether an email has been designated as spam, .e.g. if it was flagged by a user, or whether it is considered an example of regular emails (non-spam, also called \"ham\"). \n",
    "\n",
    "Our goal is to explore and compare various features space and machine learning approaches. The use of spam emails is just for demonstration and learning purpose as it is a text-based example that everyone is easily familiar with and that allows us to highlight different stages of developing a machine learning application and the decision making processes involved along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data preparation :: Overview\n",
    "\n",
    "In this notebook we will explore the dataset, do a first analysis and prepare it for different machine learning tasks.\n",
    "\n",
    "### Task \n",
    "\n",
    "We will process the raw data, clean the text and extract additional features ain order to prepare it for further analysis and for building our machine learning models.\n",
    "\n",
    "### Notebook overview\n",
    "\n",
    "* Load the data\n",
    "* Text preprocessing\n",
    "* Feature extraction\n",
    "* Store cleaned data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries and helper functions\n",
    "%run data_prep_tools.py\n",
    "%run EDA_tools.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8546 emails loaded\n",
      "Cleaning data set:\n",
      "2710 duplicate emails found and removed\n",
      "4 empty emails found and removed\n",
      "\n",
      "5832 emails remaining\n",
      "\n",
      "Number of columns: 2\n",
      "Columns names:\n",
      "spam_label, text\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "df_source = load_source_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "spam_label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "109702c0-5f3a-4950-a82b-09b93db936fd",
       "rows": [
        [
         "845",
         "1",
         "<html> <head> <title>The Soft2Reg Team</title> </head> <link rel=STYLESHEET type=text/css href=css/main.css> <STYLE type=text/css> .Black11 {FONT-SIZE: 11px; COLOR: black; FONT-FAMILY: Verdana; FONT-WEIGHT: normal; TEXT-DECORATION: none} .Red13 {font-size : 13px; font-family :Verdana, Arial, Helvetica, sans-serif;font-weight : bold;color : Red} </style> <body bgcolor=ffffff> <center> <table border=0 width=600 cellpadding=2 cellspacing=0> <tr> <td width=275> <a href=http://www.soft2reg.com> <img src=http://www.soft2reg.com/images/logo.gif border=0 alt=www.soft2reg ></a> </td> <td align=right width=100%> <hr size=0> </td> </tr> </table> <p> <table border=0 width=600 cellpadding=4 cellspacing=0 bgcolor=6699cc> <tr> <td> <font face=arial size=+1 color=000000> <b>Soft2reg.com -- Service Update</b></font> </td> </tr> </table> <p> <table border=0 width=600 cellpadding=4 cellspacing=0> <tr> <td class=Black11> Hello,<br><br> <br>We apologize for the unsolicited e-mail, but we have noticed that you are using an online credit card processor on your web site that charges you much more than what you should be paying. <br><br> We are Soft2Reg.com and we <b>specialize in low cost online credit card processing for developers of electronic products</b>. Our rates are the lowest in the industry - <span class=Red13>8% flat fee</span> for all online credit card transactions. We provide you with a link for every one of your products that contains your logo and you put it on your web site for seamless credit card processing integration. For that simple, yet efficient service we charge only 8% of your online sales. <br><br> If you would like to see more information about us, please visit <a href=http://www.soft2reg.com>http://www.soft2reg.com</a>. <br><br> <HR noShade SIZE=1> <br>Thank you, <br>The Soft2Reg Team <br>----------------------------------- <br><a href=http://www.soft2reg.com>www.soft2reg.com</a>. </td></tr></table> </center> </body> </html>"
        ],
        [
         "2256",
         "0",
         "URL: http://diveintomark.org/archives/2002/09/23.html#now_heavily_medicated Date: 2002-09-23T16:11:02-05:00 Trust me when I tell you that heavy medication and RDF do not mix. Here is a list of things I intend to re-read once the fog lifts: - _Phil Ringnalda_: Using FOAF relationships[1] and Just say no to Trackback in index.html[2]. - _Les Orchard_: Per-post comment RSS feed[3]. - _Phil Wainewright_: The bare necessities of RSS[4] and What to do about RDF [5]. The beginning of an RSS 2.0 best practices document. - _Jonathon Delacour_: Trying to score a goal[6]. &#8220;As the best and the brightest focus on the possibilities of FOAF, I turned my attention to yesterday's news: RSS.&#8221; No, RSS will always be today's news. Get it? Today's newzzz... Never mind. - Comments on Ben Hammersley's Friend of a Friend[7]. Various ways to link to a FOAF file from an RSS feed. - _Nicholas Chase_: The Web's future: XHTML 2.0[8]. We're losing backward compatibility, isn't that great? Well, he seems to think so. - mod_cc[9], a module for including copyright information in RDF documents such as RSS 1.0 feeds, and, I hope, FOAF files. - _Shelley Powers_: Who is your audience, and what are you trying to accomplish?[10] Addressing the growing identity crisis on the RSS-DEV mailing list[11]. Also the comments on Shelley's article[12]. - _Ian Hickson_: Pingback 1.0[13]. &#8220;The best thing about this idea is that unlike similar schemes like TrackBack, it is totally transparent to both users.&#8221; - New software helps in building of accessible web sites[14]. A press release for a new edition of LIFT[15], which I have never used. - Forget Mars bars, Twinkies now the deep-fried treat[16]. &#8220;The secret to making a deep-fried Twinkie, he says, is to place it in the fridge first to give it more stability. He then rolls it in flour, covers it with batter ... and plunks it into the oil.&#8221; [1] http://philringnalda.com/archives/002324.php [2] http://philringnalda.com/archives/002329.php [3] http://www.decafbad.com/news_archives/000290.phtml [4] http://howto.looselycoupled.com/blog/2002_09_15_dy.htm [5] http://howto.looselycoupled.com/blog/2002_09_22_dy.htm#85480973 [6] http://weblog.delacour.net/archives/000707.html [7] http://rss.benhammersley.com/archives/001387.html [8] http://www-106.ibm.com/developerworks/library/wa-xhtml/?n-wa-9192 [9] http://web.resource.org/rss/1.0/modules/cc/ [10] http://weblog.burningbird.net/archives/000541.php [11] http://groups.yahoo.com/group/rss-dev/ [12] http://burningbird.net/cgi-bin/mt-comments.cgi?entry_id=541 [13] http://ln.hixie.ch/?start=1032794857&count=1 [14] http://maccentral.macworld.com/news/0209/23.usable.php [15] http://www.usablenet.com/ [16] http://www.globeandmail.com/servlet/ArticleNews/PEstory/TGAM/20020923/UFATTN/Headlines/headdex/headdexInternational_temp/13/13/22/"
        ],
        [
         "3915",
         "0",
         "To update spamassasin, all I need to do is install the new tar.gz file as if it were a new installation? I don't need to stop incoming mail or anything like that? Thanks, Mike -- Michael Clark, Webmaster Center for Democracy and Technology 1634 Eye Street NW, Suite 1100 Washington, DC 20006 voice: 202-637-9800 http://www.cdt.org/ Join our Activist Network! Your participation can make a difference! http://www.cdt.org/join/ ------------------------------------------------------- This sf.net email is sponsored by: Jabber - The world's fastest growing real-time communications platform! Don't just IM. Build it in! http://www.jabber.com/osdn/xim _______________________________________________ Spamassassin-talk mailing list Spamassassin-talk@lists.sourceforge.net https://lists.sourceforge.net/lists/listinfo/spamassassin-talk"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam_label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;html&gt; &lt;head&gt; &lt;title&gt;The Soft2Reg Team&lt;/title&gt; &lt;/head&gt; &lt;link rel=STYLESHEET type=text/css href=css/main.css&gt; &lt;STYLE type=text/css&gt; .Black11 {FONT-SIZE: 11px; COLOR: black; FONT-FAMILY: Verdana; FONT-WEIGHT: normal; TEXT-DECORATION: none} .Red13 {font-size : 13px; font-family :Verdana, Arial, Helvetica, sans-serif;font-weight : bold;color : Red} &lt;/style&gt; &lt;body bgcolor=ffffff&gt; &lt;center&gt; &lt;table border=0 width=600 cellpadding=2 cellspacing=0&gt; &lt;tr&gt; &lt;td width=275&gt; &lt;a href=http://www.soft2reg.com&gt; &lt;img src=http://www.soft2reg.com/images/logo.gif border=0 alt=www.soft2reg &gt;&lt;/a&gt; &lt;/td&gt; &lt;td align=right width=100%&gt; &lt;hr size=0&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;p&gt; &lt;table border=0 width=600 cellpadding=4 cellspacing=0 bgcolor=6699cc&gt; &lt;tr&gt; &lt;td&gt; &lt;font face=arial size=+1 color=000000&gt; &lt;b&gt;Soft2reg.com -- Service Update&lt;/b&gt;&lt;/font&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;p&gt; &lt;table border=0 width=600 cellpadding=4 cellspacing=0&gt; &lt;tr&gt; &lt;td class=Black11&gt; Hello,&lt;br&gt;&lt;br&gt; &lt;br&gt;We apologize for the unsolicited e-mail, but we have noticed that you are using an online credit card processor on your web site that charges you much more than what you should be paying. &lt;br&gt;&lt;br&gt; We are Soft2Reg.com and we &lt;b&gt;specialize in low cost online credit card processing for developers of electronic products&lt;/b&gt;. Our rates are the lowest in the industry - &lt;span class=Red13&gt;8% flat fee&lt;/span&gt; for all online credit card transactions. We provide you with a link for every one of your products that contains your logo and you put it on your web site for seamless credit card processing integration. For that simple, yet efficient service we charge only 8% of your online sales. &lt;br&gt;&lt;br&gt; If you would like to see more information about us, please visit &lt;a href=http://www.soft2reg.com&gt;http://www.soft2reg.com&lt;/a&gt;. &lt;br&gt;&lt;br&gt; &lt;HR noShade SIZE=1&gt; &lt;br&gt;Thank you, &lt;br&gt;The Soft2Reg Team &lt;br&gt;----------------------------------- &lt;br&gt;&lt;a href=http://www.soft2reg.com&gt;www.soft2reg.com&lt;/a&gt;. &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; &lt;/center&gt; &lt;/body&gt; &lt;/html&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>0</td>\n",
       "      <td>URL: http://diveintomark.org/archives/2002/09/23.html#now_heavily_medicated Date: 2002-09-23T16:11:02-05:00 Trust me when I tell you that heavy medication and RDF do not mix. Here is a list of things I intend to re-read once the fog lifts: - _Phil Ringnalda_: Using FOAF relationships[1] and Just say no to Trackback in index.html[2]. - _Les Orchard_: Per-post comment RSS feed[3]. - _Phil Wainewright_: The bare necessities of RSS[4] and What to do about RDF [5]. The beginning of an RSS 2.0 best practices document. - _Jonathon Delacour_: Trying to score a goal[6]. &amp;#8220;As the best and the brightest focus on the possibilities of FOAF, I turned my attention to yesterday's news: RSS.&amp;#8221; No, RSS will always be today's news. Get it? Today's newzzz... Never mind. - Comments on Ben Hammersley's Friend of a Friend[7]. Various ways to link to a FOAF file from an RSS feed. - _Nicholas Chase_: The Web's future: XHTML 2.0[8]. We're losing backward compatibility, isn't that great? Well, he seems to think so. - mod_cc[9], a module for including copyright information in RDF documents such as RSS 1.0 feeds, and, I hope, FOAF files. - _Shelley Powers_: Who is your audience, and what are you trying to accomplish?[10] Addressing the growing identity crisis on the RSS-DEV mailing list[11]. Also the comments on Shelley's article[12]. - _Ian Hickson_: Pingback 1.0[13]. &amp;#8220;The best thing about this idea is that unlike similar schemes like TrackBack, it is totally transparent to both users.&amp;#8221; - New software helps in building of accessible web sites[14]. A press release for a new edition of LIFT[15], which I have never used. - Forget Mars bars, Twinkies now the deep-fried treat[16]. &amp;#8220;The secret to making a deep-fried Twinkie, he says, is to place it in the fridge first to give it more stability. He then rolls it in flour, covers it with batter ... and plunks it into the oil.&amp;#8221; [1] http://philringnalda.com/archives/002324.php [2] http://philringnalda.com/archives/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3915</th>\n",
       "      <td>0</td>\n",
       "      <td>To update spamassasin, all I need to do is install the new tar.gz file as if it were a new installation? I don't need to stop incoming mail or anything like that? Thanks, Mike -- Michael Clark, Webmaster Center for Democracy and Technology 1634 Eye Street NW, Suite 1100 Washington, DC 20006 voice: 202-637-9800 http://www.cdt.org/ Join our Activist Network! Your participation can make a difference! http://www.cdt.org/join/ ------------------------------------------------------- This sf.net email is sponsored by: Jabber - The world's fastest growing real-time communications platform! Don't just IM. Build it in! http://www.jabber.com/osdn/xim _______________________________________________ Spamassassin-talk mailing list Spamassassin-talk@lists.sourceforge.net https://lists.sourceforge.net/lists/listinfo/spamassassin-talk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      spam_label  \\\n",
       "845            1   \n",
       "2256           0   \n",
       "3915           0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 text  \n",
       "845                                       <html> <head> <title>The Soft2Reg Team</title> </head> <link rel=STYLESHEET type=text/css href=css/main.css> <STYLE type=text/css> .Black11 {FONT-SIZE: 11px; COLOR: black; FONT-FAMILY: Verdana; FONT-WEIGHT: normal; TEXT-DECORATION: none} .Red13 {font-size : 13px; font-family :Verdana, Arial, Helvetica, sans-serif;font-weight : bold;color : Red} </style> <body bgcolor=ffffff> <center> <table border=0 width=600 cellpadding=2 cellspacing=0> <tr> <td width=275> <a href=http://www.soft2reg.com> <img src=http://www.soft2reg.com/images/logo.gif border=0 alt=www.soft2reg ></a> </td> <td align=right width=100%> <hr size=0> </td> </tr> </table> <p> <table border=0 width=600 cellpadding=4 cellspacing=0 bgcolor=6699cc> <tr> <td> <font face=arial size=+1 color=000000> <b>Soft2reg.com -- Service Update</b></font> </td> </tr> </table> <p> <table border=0 width=600 cellpadding=4 cellspacing=0> <tr> <td class=Black11> Hello,<br><br> <br>We apologize for the unsolicited e-mail, but we have noticed that you are using an online credit card processor on your web site that charges you much more than what you should be paying. <br><br> We are Soft2Reg.com and we <b>specialize in low cost online credit card processing for developers of electronic products</b>. Our rates are the lowest in the industry - <span class=Red13>8% flat fee</span> for all online credit card transactions. We provide you with a link for every one of your products that contains your logo and you put it on your web site for seamless credit card processing integration. For that simple, yet efficient service we charge only 8% of your online sales. <br><br> If you would like to see more information about us, please visit <a href=http://www.soft2reg.com>http://www.soft2reg.com</a>. <br><br> <HR noShade SIZE=1> <br>Thank you, <br>The Soft2Reg Team <br>----------------------------------- <br><a href=http://www.soft2reg.com>www.soft2reg.com</a>. </td></tr></table> </center> </body> </html>  \n",
       "2256  URL: http://diveintomark.org/archives/2002/09/23.html#now_heavily_medicated Date: 2002-09-23T16:11:02-05:00 Trust me when I tell you that heavy medication and RDF do not mix. Here is a list of things I intend to re-read once the fog lifts: - _Phil Ringnalda_: Using FOAF relationships[1] and Just say no to Trackback in index.html[2]. - _Les Orchard_: Per-post comment RSS feed[3]. - _Phil Wainewright_: The bare necessities of RSS[4] and What to do about RDF [5]. The beginning of an RSS 2.0 best practices document. - _Jonathon Delacour_: Trying to score a goal[6]. &#8220;As the best and the brightest focus on the possibilities of FOAF, I turned my attention to yesterday's news: RSS.&#8221; No, RSS will always be today's news. Get it? Today's newzzz... Never mind. - Comments on Ben Hammersley's Friend of a Friend[7]. Various ways to link to a FOAF file from an RSS feed. - _Nicholas Chase_: The Web's future: XHTML 2.0[8]. We're losing backward compatibility, isn't that great? Well, he seems to think so. - mod_cc[9], a module for including copyright information in RDF documents such as RSS 1.0 feeds, and, I hope, FOAF files. - _Shelley Powers_: Who is your audience, and what are you trying to accomplish?[10] Addressing the growing identity crisis on the RSS-DEV mailing list[11]. Also the comments on Shelley's article[12]. - _Ian Hickson_: Pingback 1.0[13]. &#8220;The best thing about this idea is that unlike similar schemes like TrackBack, it is totally transparent to both users.&#8221; - New software helps in building of accessible web sites[14]. A press release for a new edition of LIFT[15], which I have never used. - Forget Mars bars, Twinkies now the deep-fried treat[16]. &#8220;The secret to making a deep-fried Twinkie, he says, is to place it in the fridge first to give it more stability. He then rolls it in flour, covers it with batter ... and plunks it into the oil.&#8221; [1] http://philringnalda.com/archives/002324.php [2] http://philringnalda.com/archives/0...  \n",
       "3915                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    To update spamassasin, all I need to do is install the new tar.gz file as if it were a new installation? I don't need to stop incoming mail or anything like that? Thanks, Mike -- Michael Clark, Webmaster Center for Democracy and Technology 1634 Eye Street NW, Suite 1100 Washington, DC 20006 voice: 202-637-9800 http://www.cdt.org/ Join our Activist Network! Your participation can make a difference! http://www.cdt.org/join/ ------------------------------------------------------- This sf.net email is sponsored by: Jabber - The world's fastest growing real-time communications platform! Don't just IM. Build it in! http://www.jabber.com/osdn/xim _______________________________________________ Spamassassin-talk mailing list Spamassassin-talk@lists.sourceforge.net https://lists.sourceforge.net/lists/listinfo/spamassassin-talk  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If you rerun this cell multiple times you get different samples displayed each time\n",
    "# OR you can replace the number 3 with a number of your choice\n",
    "display(df_source.sample(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Text preprocessing\n",
    "\n",
    "Good text preprocessing is an essential part of every NLP project. It is the first step in the machine learning pipeline and it is important to get it right. The goal of text preprocessing is to transform the raw text into a format that can be used by machine learning algorithms.\n",
    "\n",
    "Our overall goal is to build models that can help us distinguish non-spam from spam. \n",
    "\n",
    "The examples above have shown us that some samples are quite messy and contain a lot of content unnecessary for understanding the text as a human, i.e. they contain \"noise\". As a first step we will \"*clean*\" and \"*standardize*\" raw text. Our aim is to keep as many \"*informative*\" words as possible, while discarding the \"*uniformative*\" ones. Removing the noise from our texts will help to improve the accuracy of our models.\n",
    "\n",
    "We thus need to identify which parts of the text are acting as \"*noise*\" in our text and remove it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Task:\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<h3>Questions</h3>\n",
    "    \n",
    "__Q1.__ What parts of the text do you think are noise?\n",
    "   \n",
    "__Q2.__ What should we do with these parts of the text?\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Give your answer here:\n",
    "\n",
    "1.    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¡ Observations\n",
    "\n",
    "1. There are some items in the text that should be removed to make it readable. Here are some suggestions:\n",
    "\n",
    "* HTML tags \n",
    "* URLs\n",
    "* E-mail addresses\n",
    "* Punctuation marks, digits (e.g. 2002, 1.1, ...)\n",
    "* Multiple whitespaces\n",
    "* Case conversion (e.g. Dog vs dog, ...)\n",
    "* English STOPWORDS (e.g. a, is, my, i, all, and, by...)\n",
    "* ...\n",
    "\n",
    "2. From experience, we know that the number of occurrences of the above items (HTML tags, URLs, etc) can be helpful to distinguish spam from non-spam. Similarly, the length of the emails and the frequency of punctuation marks or upper case letters could also give us clues as to whether we are dealing with spam or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *clean_corpus* function below will take care of the parts raised in the 1st set of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 5832\n",
      "Number of columns: 3\n",
      "Columns names:\n",
      "spam_label, text, text_cleaned\n",
      "\n",
      "Number of duplicate cleaned texts found: 279\n",
      "Number of empty texts found: 27\n",
      "\n",
      "Email texts cleaned\n",
      "Number of samples: 5832\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = clean_corpus(df_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original document:\n",
      "\n",
      "Best bang for the buck: 390 hp Mustang Cobra @ $35k. GG, recently emerged from the passenger side of\n",
      "a 2003 with the largest smile. -----Original Message----- From: fork-admin@xent.com [mailto:fork-\n",
      "admin@xent.com]On Behalf Of Joseph S. Barrera III Sent: Sunday, December 01, 2002 1:40 PM To:\n",
      "fork@spamassassin.taint.org Subject: Re: Mercedes-Benz G55 On the other end of the spectrum, I just\n",
      "bought a Honda del Sol for my new commute to San Jose (from San Bruno)... I wonder if it would fit\n",
      "in the cargo area of a G55. - Joe\n",
      "\n",
      "Cleaned document:\n",
      "\n",
      "best bang buck mustang cobra recently emerged passenger largest smile original message behalf joseph\n",
      "barrera sent sunday december subject mercedes benz spectrum just bought honda commute jose bruno\n",
      "wonder cargo area\n"
     ]
    }
   ],
   "source": [
    "# Let's look at some examples.\n",
    "# You can rerun this cell to get a different sample\n",
    "show_clean_text(df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering \n",
    "\n",
    "## Part 1: Extracting numeric features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the ideas from the 2nd observation and create new features that count different noise components of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples and columns of input: (5832, 2)\n",
      "Number of columns: 2\n",
      "Columns names:\n",
      "spam_label, text\n",
      "\n",
      "Numeric features extracted\n",
      "Data size: (5832, 14)\n",
      "Number of columns: 14\n",
      "Columns names:\n",
      "email_counts, html tag_counts, url_counts, Twitter username_counts, hashtag_counts\n",
      "character_counts, word_counts, unique word_counts, punctuation mark_counts, uppercase word_counts\n",
      "lowercase word_counts, digit_counts, alphabetic char_counts, spam_label\n",
      "Numeric features saved to data/num_features.csv\n"
     ]
    }
   ],
   "source": [
    "num_features_df = extract_numeric_features(df=df_source, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "## Part 2: Extracting features from text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computers don't understand natural language and its unstructured form. So, how do we represent text?\n",
    "\n",
    "### Bag of words\n",
    "\n",
    "One of the simplest but in the early days of NLP effective and commonly used models to represent text for machine learning is the ***Bag of Words*** model ([link](https://en.wikipedia.org/wiki/Bag-of-words_model)). When using this model, we discard most of the structure of the input text (word order, chapters, paragraphs, sentences or formatting) and only count how often each word appears in each text. Discarding the structure and counting only word occurrences leads to the mental image of representing text as a \"bag\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Example:** Let our toy corpus contain four documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "corpus = [\n",
    "    'I enjoy paragliding.',\n",
    "    'I do like NLP.',\n",
    "    'I like deep learning.',\n",
    "    'O Captain! my Captain!'\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "captain",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "deep",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "do",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "enjoy",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "i",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "learning",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "like",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "my",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "nlp",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "o",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "paragliding",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "d606f7d0-9a5b-44fc-bedd-40ef0f8b5cbd",
       "rows": [
        [
         "I enjoy paragliding.",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1"
        ],
        [
         "I do like NLP.",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "1",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "I like deep learning.",
         "0",
         "1",
         "0",
         "0",
         "1",
         "1",
         "1",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "O Captain! my Captain!",
         "2",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>captain</th>\n",
       "      <th>deep</th>\n",
       "      <th>do</th>\n",
       "      <th>enjoy</th>\n",
       "      <th>i</th>\n",
       "      <th>learning</th>\n",
       "      <th>like</th>\n",
       "      <th>my</th>\n",
       "      <th>nlp</th>\n",
       "      <th>o</th>\n",
       "      <th>paragliding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I enjoy paragliding.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I do like NLP.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I like deep learning.</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O Captain! my Captain!</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        captain  deep  do  enjoy  i  learning  like  my  nlp  \\\n",
       "Text                                                                           \n",
       "I enjoy paragliding.          0     0   0      1  1         0     0   0    0   \n",
       "I do like NLP.                0     0   1      0  1         0     1   0    1   \n",
       "I like deep learning.         0     1   0      0  1         1     1   0    0   \n",
       "O Captain! my Captain!        2     0   0      0  0         0     0   1    0   \n",
       "\n",
       "                        o  paragliding  \n",
       "Text                                    \n",
       "I enjoy paragliding.    0            1  \n",
       "I do like NLP.          0            0  \n",
       "I like deep learning.   0            0  \n",
       "O Captain! my Captain!  1            0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_bag_of_words_vector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the table above, each column represents a word from the corpus and each row one of the four documents. The value in each cell represents the number of times that word appears in a specific document. For example, the fourth document has the word `captain` occurring twice and the words `my` and `O` occurring once.\n",
    "\n",
    "The technical implementation of  Bag of Words is called a CountVectorizer. It converts each document into a rows of numbers, i.e. a numeric vector. Thus the name vectorizer.  \n",
    "\n",
    "While this kind of transformation allows machine learning algorithms to process text data effectively, it has a drawback. It treats all words as independent and ignores the context in which they appear. For example, losing information about the order of the words in the text can change the meaning of a sentence. The sentences \"I do like NLP\", \"Do I like NLP\" or \"NLP like I do\" have the same set of words but different meanings. \n",
    "\n",
    "### TF-IDF\n",
    "\n",
    "The **Term Frequencyâ€“Inverse Document Frequency** approach aims to address this limitation, by measuring how important a word is for a document relative to a collection of documents (the corpus). \n",
    "\n",
    "We use the implementation by scikit-learn. It calculates the TF-IDF score as the product of :\n",
    "- The **term frequency TF**, which is the ratio of the frequency of the word $w$ in the given document $d$ divided by the total number of words in the given document.   \n",
    "  So $TF(w, d) = \\frac{f(w, d)}{N(d)}$\n",
    "- and the (smoothed) )**inverse document frequency IDF**, which is given by \n",
    "$$IDF(w, D) = \\log\\left(\\frac{size(D)+1}{df(w, D)+1}\\right)+1$$ \n",
    "where $df(w, D)$ is the number of documents in the corpus $D$ that contain the word $w$. Adding `1` in the numerator and denominator keeps the IDF value finite and stable.\n",
    "\n",
    "This way, common words that appear in many documents (small IDF) are given less weight while rare words that appear in only a few documents get a higher weight (high IDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "captain",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "deep",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "do",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "enjoy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "i",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "learning",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "like",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "my",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "nlp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "o",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "paragliding",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "5f6407e7-cd0b-40d4-96b7-03e58080d220",
       "rows": [
        [
         "I enjoy paragliding.",
         "0.0",
         "0.0",
         "0.0",
         "0.6445029922609534",
         "0.41137791133379387",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.6445029922609534"
        ],
        [
         "I do like NLP.",
         "0.0",
         "0.0",
         "0.5745795256791941",
         "0.0",
         "0.3667466683744504",
         "0.0",
         "0.4530050977381881",
         "0.0",
         "0.5745795256791941",
         "0.0",
         "0.0"
        ],
        [
         "I like deep learning.",
         "0.0",
         "0.5745795256791941",
         "0.0",
         "0.0",
         "0.3667466683744504",
         "0.5745795256791941",
         "0.4530050977381881",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "O Captain! my Captain!",
         "0.816496580927726",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.408248290463863",
         "0.0",
         "0.408248290463863",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>captain</th>\n",
       "      <th>deep</th>\n",
       "      <th>do</th>\n",
       "      <th>enjoy</th>\n",
       "      <th>i</th>\n",
       "      <th>learning</th>\n",
       "      <th>like</th>\n",
       "      <th>my</th>\n",
       "      <th>nlp</th>\n",
       "      <th>o</th>\n",
       "      <th>paragliding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I enjoy paragliding.</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.644503</td>\n",
       "      <td>0.411378</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.644503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I do like NLP.</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.57458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366747</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.453005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I like deep learning.</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57458</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366747</td>\n",
       "      <td>0.57458</td>\n",
       "      <td>0.453005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O Captain! my Captain!</th>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         captain     deep       do     enjoy         i  \\\n",
       "Text                                                                     \n",
       "I enjoy paragliding.    0.000000  0.00000  0.00000  0.644503  0.411378   \n",
       "I do like NLP.          0.000000  0.00000  0.57458  0.000000  0.366747   \n",
       "I like deep learning.   0.000000  0.57458  0.00000  0.000000  0.366747   \n",
       "O Captain! my Captain!  0.816497  0.00000  0.00000  0.000000  0.000000   \n",
       "\n",
       "                        learning      like        my      nlp         o  \\\n",
       "Text                                                                      \n",
       "I enjoy paragliding.     0.00000  0.000000  0.000000  0.00000  0.000000   \n",
       "I do like NLP.           0.00000  0.453005  0.000000  0.57458  0.000000   \n",
       "I like deep learning.    0.57458  0.453005  0.000000  0.00000  0.000000   \n",
       "O Captain! my Captain!   0.00000  0.000000  0.408248  0.00000  0.408248   \n",
       "\n",
       "                        paragliding  \n",
       "Text                                 \n",
       "I enjoy paragliding.       0.644503  \n",
       "I do like NLP.             0.000000  \n",
       "I like deep learning.      0.000000  \n",
       "O Captain! my Captain!     0.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_tfidf_vector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can extract the text features using either the CountVectorizer (`vectorizer=\"count\"`) or the TfidfVectorizer (`vectorizer=\"tfidf\"`). Please note that this process takes a while, so be patient.\n",
    "\n",
    "For that reason, we have already pre-computed the features using `\"tfidf\"`and stored them in the `features` folder. You can load them using the command `load_feature_space(features=\"text\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorizer selected\n",
      "Number of columns: 10001\n",
      "First 5 names:\n",
      "aalib, aall, aaron, abacha, abandon\n",
      "Last 5 columns:\n",
      "zoom, zope, zurich, zyban, spam_label\n",
      "Text features saved to data/text_features_tfidf.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5832, 10001)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features_df = extract_text_features(\n",
    "    df_cleaned, vectorizer=\"tfidf\", with_labels=True, store=True\n",
    ")\n",
    "text_features_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings\n",
    "\n",
    "The Bag of Words and TF-IDF approaches cannot capture the meaning of words or the relationships between them. They also lead to very high-dimensional and sparse representations of the text which are not very efficient and can lead to overfitting.\n",
    "To address these limitations, we can use **embeddings** or transformer based models. Embeddings are denser vector representations of words are learned from large corpora of text. By representing similar words as similar vectors they can capture meaning and relationships in a continuous lower-dimensional vector space.\n",
    "\n",
    "We have passed the email texts through a language model to generate the associated embeddings. Since the feature extraction takes some time we have stored these embeddings and made them available for you in the file named `email_embeddings.csv`.\n",
    "\n",
    "You can load them using the command `load_feature_space(features=\"embeddings\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email embeddings loaded\n",
      "Data includes labels in the column 'spam_label'\n",
      "The data set has 5832 rows, 769 columns\n"
     ]
    }
   ],
   "source": [
    "embeddings_df = load_feature_space(features=\"embedding\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adsml2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
