{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup Google Colab by running this cell only once (ignore this if run locally) {display-mode: \"form\"}\n",
    "import sys\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    # Clone GitHub repository\n",
    "    !git clone https://github.com/epfl-exts/aiml2days.git\n",
    "        \n",
    "    # Copy files required to run the code\n",
    "    !cp -r \"aiml2days/notebooks/data\" \"aiml2days/notebooks/data_prep_tools.py\" \"aiml2days/notebooks/EDA_tools.py\" \"aiml2days/notebooks/modeling_tools.py\" . \n",
    "    \n",
    "    # Install packages via pip\n",
    "    !pip install -r \"aiml2days/colab-requirements.txt\"\n",
    "    \n",
    "    # Restart Runtime\n",
    "    import os\n",
    "    os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries and helper functions\n",
    "%run data_prep_tools.py\n",
    "%run EDA_tools.py\n",
    "%run modeling_tools.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "In the data preparation notebook we loaded a dataset containing ~6'000 labeled emails (spam and non-spam). We explored the email texts and decided on some procedures to clean the email text and extract both numerical features counting \"spammish signatures\" and text features. We also extracted embeddings of the original email text from a language model.\n",
    "\n",
    "### Loading features  \n",
    "\n",
    "All three feature spaces can be loaded using the `load_feature_space()`function.  \n",
    "\n",
    "The parameter `features` specifies which of the above features you want to load. The options are:\n",
    "\n",
    "The different feature sets can be loaded with the `load_feature_space()`-function. The feature sets are specified with the `features` parameter. The options are:\n",
    "* \"num\": numerical features\n",
    "* \"text\": (default) text features\n",
    "* \"num_text\": numerical and text features combined\n",
    "* \"embedding\": embedding features\n",
    "  \n",
    "The parameter `no_labels` controls whether we want to omit the labels. The options for are:\n",
    "- `True` to omit the labels\n",
    "- `False` (default) to load the labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Task \n",
    "\n",
    "Explore the different feature spaces.\n",
    "\n",
    "Disclaimer: For easy of analysis we will analyze the full data set. In practice when building a supervised learning model like a spam filter you create a training set and a test set. You can explore the training set and used the insights to build your model. But you don't explore the test set as it is used to evaluate the performance of the model on unseen data. \n",
    "\n",
    "### Notebook overview\n",
    "\n",
    "* Explore the numeric features\n",
    "* Explore the text features\n",
    "* Explore the embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = load_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by exploring the distribution of the labels i.e. how many spam and non-spam emails we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h3>Questions</h3>\n",
    "    \n",
    "__Q1.__ What do you observe for the frequency of spam and non-spam emails? \n",
    "\n",
    "__Q2.__ How could that impact the training of the spam detector?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_class_frequency(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "Add your obsevation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the features\n",
    "\n",
    "### Numeric features\n",
    " The numeric features are:\n",
    "- \"email_counts\"\n",
    "- \"html tag_counts\"\n",
    "- \"url_counts\"\n",
    "- \"Twitter username_counts\"\n",
    "- \"hashtag_counts\"\n",
    "- \"character_counts\"\n",
    "- \"word_counts\"\n",
    "- \"unique word_counts\"\n",
    "- \"punctuation mark_counts\"\n",
    "- \"uppercase word_counts\"\n",
    "- \"lowercase word_counts\"\n",
    "- \"digit_counts\"\n",
    "- \"alphabetic char_counts\"\n",
    "\n",
    "Note some features have been log-scaled.\n",
    "\n",
    "#### Load the numeric features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features_df = load_feature_space(features=\"num\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the distributions of the numeric features \n",
    "- once across the full corpus and\n",
    "- once by `spam_label`   \n",
    "\n",
    "and see whether there are signs of differences between spam and non-spam emails.\n",
    "\n",
    "#### Full corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numeric_features(num_features_df, with_labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By `spam_label`:\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<h3>Questions</h3>\n",
    "    \n",
    "__Q1.__ Do spam and non-spam emails differ on average acorss different numeric features?\n",
    "\n",
    "* Do spams contain more HTML tags? \n",
    "* Does non-spam contain more URLs and E-mail adresses? \n",
    "* Are spams mails longer than non-spam? \n",
    "* ...\n",
    "   \n",
    "__Q2.__ Could these features be useful for the distinction of spam and non-spam emails?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numeric_features(num_features_df, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "Add your obsevation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text features\n",
    "\n",
    "It is easier to work with the cleaned text before we applied the vectorizers to generate a specific feature space.\n",
    "\n",
    "#### Load the cleaned text::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source = load_source_data(verbose=False)\n",
    "df_cleaned = clean_corpus(df_source, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "\n",
    "<h3>Questions</h3>\n",
    "\n",
    "Let's explore the cleaned text for the most common words overall. You can change `N` to show more or less words.\n",
    "\n",
    "__Q1.__ Which words do you think are more indicative of spam, and which are more typical of non-spam?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Give your answer here:\n",
    "\n",
    "1.    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_most_common_words(df_cleaned, N=30, with_labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "\n",
    "<h3>Questions</h3>\n",
    "\n",
    "Now let's explore the most common words in each class. We are taking the top `N` words from each class and combining them into one set. We then plot the total counts of all these words for both classes. Thus you will get more than `N` words in the plot. The words are sorted by their frequency in the non-spam class (blue).\n",
    "\n",
    "You can change `N` to show more or less words.\n",
    "\n",
    "__Q1.__ Which words do you think are more indicative of spam, and which are more typical of non-spam?\n",
    "\n",
    "__Q2.__ Are the total counts representative of the importance to each class?\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_most_common_tokens(df_cleaned, N=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Give your answer here:\n",
    "\n",
    "1.    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "\n",
    "<h3>Questions</h3>\n",
    "\n",
    "Let's repeat the above counts but this time we account for the different class sizes. We will use the relative frequencies adjusted by adjusting our counts to 1000 documents per class.\n",
    "\n",
    "__Q1.__ Which words do you think are more indicative of spam, and which are more typical of non-spam?\n",
    "\n",
    "__Q2.__ What has changed in terms of words that appear to be good indicators for either class?\n",
    "\n",
    "__Q3.__ Playing around a bit with `N`, do you think building a model based on text features can yield some good results?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_most_common_tokens(df_cleaned, N=15, per_1000=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Give your answer here:\n",
    "\n",
    "1.    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the embedding space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df = load_feature_space(features=\"embedding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA \n",
    "We run a PCA on the embedding space to see if we can reduce the dimension of needed for the embedding space.  \n",
    "The PCA is run on the full data set. We extract how many components explain a certain amount of variance and visualize the results using a scree plot and a table.\n",
    "\n",
    "We will also visualize the first two components in a scatter plot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "\n",
    "<h3>Questions</h3>\n",
    "\n",
    "Now let's explore the most common words in each class. We are taking the top `N` words from each class and combining them into one set. We then plot the total counts of all these words for both classes. Thus you will get more than `N` words in the plot. The words are sorted by their frequency in the non-spam class (blue).\n",
    "\n",
    "You can change `N` to show more or less words.\n",
    "\n",
    "__Q1.__ How much variance is explained by the first two components?\n",
    "\n",
    "__Q2.__ By how much could the feature space shrink if we wanted to retain 90% of variance?\n",
    "\n",
    "__Q3.__ Looking at the scatterplot, what insights can you draw from the PCA results regarding class separation? \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_pca_df = run_pca(embeddings_df, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Give your answer here:\n",
    "\n",
    "1.    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adsml2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
